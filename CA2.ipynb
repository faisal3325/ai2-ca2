{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CA-2"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def time_elapsed_start():\n",
    "    return time.time()\n",
    "\n",
    "def time_elapsed_stop(start):\n",
    "    sec = time.time() - start\n",
    "    min = sec/60\n",
    "    hour = min/60\n",
    "    print(f\"Execution took {sec} seconds - ({min} minutes), ({hour} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "ROWS_TO_READ = 200000\n",
    "df = pd.read_csv('quora_questions.csv', nrows=ROWS_TO_READ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                 question\n114733  I am a future European student that wants to a...\n172622                                 Is India changing?\n173428  What is the detailed difference between electr...\n19786                              Who designed BHIM app?\n193298                          How do you became a jerk?",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>114733</th>\n      <td>I am a future European student that wants to a...</td>\n    </tr>\n    <tr>\n      <th>172622</th>\n      <td>Is India changing?</td>\n    </tr>\n    <tr>\n      <th>173428</th>\n      <td>What is the detailed difference between electr...</td>\n    </tr>\n    <tr>\n      <th>19786</th>\n      <td>Who designed BHIM app?</td>\n    </tr>\n    <tr>\n      <th>193298</th>\n      <td>How do you became a jerk?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "What is the step by step guide to invest in share market in india?\nWhat is the story of Kohinoor (Koh-i-Noor) Diamond?\nHow can I increase the speed of my internet connection while using a VPN?\nWhy am I mentally very lonely? How can I solve it?\nWhich one dissolve in water quikly sugar, salt, methane and carbon di oxide?\nAstrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\nShould I buy tiago?\nHow can I be a good geologist?\nWhen do you use ã‚· instead of ã—?\nMotorola (company): Can I hack my Charter Motorolla DCX3400?\n"
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(df['question'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dataframe size: 200000\n"
    }
   ],
   "source": [
    "# dataframe size|\n",
    "print(f\"Dataframe size: {df.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are considering that a word should come in atleast 2 documents and should not come in more than 90% of the documents."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(question):\n",
    "    question = question.lower()\n",
    "    question = re.sub(r'[%s]' % re.escape(string.punctuation), '', question)\n",
    "    question = re.sub(r'[^A-Za-z0-9]+ ', '', question)\n",
    "    return question\n",
    "\n",
    "df_clean = pd.DataFrame(df.question.apply(lambda x: clean(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "what is the step by step guide to invest in share market in india\nwhat is the story of kohinoor kohinoor diamond\nhow can i increase the speed of my internet connection while using a vpn\nwhy am i mentally very lonely how can i solve it\nwhich one dissolve in water quikly sugar salt methane and carbon di oxide\nastrology i am a capricorn sun cap moon and cap risingwhat does that say about me\nshould i buy tiago\nhow can i be a good geologist\nwhen do you useinstead of ã—\nmotorola company can i hack my charter motorolla dcx3400\n"
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(df_clean['question'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                 question\n45798              why am i losing interest in everything\n5034            does the tv show preacher have any nudity\n23834                       whats are the meaning of life\n145527                        how can i stop my hair fall\n93314   how were new horizons rosetta mars missions an...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>45798</th>\n      <td>why am i losing interest in everything</td>\n    </tr>\n    <tr>\n      <th>5034</th>\n      <td>does the tv show preacher have any nudity</td>\n    </tr>\n    <tr>\n      <th>23834</th>\n      <td>whats are the meaning of life</td>\n    </tr>\n    <tr>\n      <th>145527</th>\n      <td>how can i stop my hair fall</td>\n    </tr>\n    <tr>\n      <th>93314</th>\n      <td>how were new horizons rosetta mars missions an...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df_clean.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):        \n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)\n",
    "    \n",
    "df_clean[\"question_clean\"] =  df_clean.apply(lambda x: lemmatizer(x['question']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['question_clean'] = df_clean['question_clean'].str.replace('-PRON-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                 question  \\\n196368  how do infrasonic and ultrasonic sound waves d...   \n184708        what would happen if porn suddenly vanished   \n119926   where is the best spoken english classes in pune   \n163801             how much should i pay a college intern   \n70302   what are tracer rounds are they legal for the ...   \n\n                                           question_clean  \n196368  how do infrasonic and ultrasonic sound wave di...  \n184708          what would happen if porn suddenly vanish  \n119926     where be the good spoken english class in pune  \n163801             how much should i pay a college intern  \n70302   what be tracer round be  legal for the public ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>question_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>196368</th>\n      <td>how do infrasonic and ultrasonic sound waves d...</td>\n      <td>how do infrasonic and ultrasonic sound wave di...</td>\n    </tr>\n    <tr>\n      <th>184708</th>\n      <td>what would happen if porn suddenly vanished</td>\n      <td>what would happen if porn suddenly vanish</td>\n    </tr>\n    <tr>\n      <th>119926</th>\n      <td>where is the best spoken english classes in pune</td>\n      <td>where be the good spoken english class in pune</td>\n    </tr>\n    <tr>\n      <th>163801</th>\n      <td>how much should i pay a college intern</td>\n      <td>how much should i pay a college intern</td>\n    </tr>\n    <tr>\n      <th>70302</th>\n      <td>what are tracer rounds are they legal for the ...</td>\n      <td>what be tracer round be  legal for the public ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df_clean.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "what be the step by step guide to invest in share market in india\nwhat be the story of kohinoor kohinoor diamond\nhow can i increase the speed of  internet connection while use a vpn\nwhy be i mentally very lonely how can i solve \nwhich one dissolve in water quikly sugar salt methane and carbon di oxide\nastrology i be a capricorn sun cap moon and cap risingwhat do that say about \nshould i buy tiago\nhow can i be a good geologist\nwhen do  useinstead of ã—\nmotorola company can i hack  charter motorolla dcx3400\n"
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(df_clean['question_clean'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer(max_df=0.9, min_df=5, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Execution took 3.8101696968078613 seconds - (0.06350282828013103 minutes), (0.001058380471335517 hours)\n"
    }
   ],
   "source": [
    "start = time_elapsed_start()\n",
    "term_matrix = count_vectorizer.fit_transform(df_clean['question_clean'])\n",
    "time_elapsed_stop(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<200000x12305 sparse matrix of type '<class 'numpy.int64'>'\n\twith 899423 stored elements in Compressed Sparse Row format>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "term_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector has taken 27,884 words in the vocabulary from 2,00,000 questions(rows)."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying LDA"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=14, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Execution took 357.62371921539307 seconds - (5.960395320256551 minutes), (0.09933992200427585 hours)\n"
    }
   ],
   "source": [
    "start = time_elapsed_start()\n",
    "lda.fit(term_matrix)\n",
    "time_elapsed_stop(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking log likelihood, perplexity"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Execution took 74.32639718055725 seconds - (1.2387732863426208 minutes), (0.02064622143904368 hours)\n"
    }
   ],
   "source": [
    "start = time_elapsed_start()\n",
    "log_likelihood = lda.score(term_matrix)\n",
    "perplexity = lda.perplexity(term_matrix)\n",
    "time_elapsed_stop(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Log likelihood: -7269604.801724052\nPerplexity: 2538.1978778472244\n"
    }
   ],
   "source": [
    "print(f\"Log likelihood: {log_likelihood}\")\n",
    "print(f\"Perplexity: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a metrics dataframe for comparison later\n",
    "lda_metrics_df = pd.DataFrame([[log_likelihood, perplexity, 13, 0.7]], columns=['log_likelihood', 'perplexity', 'n_components', 'learning_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   log_likelihood   perplexity  n_components  learning_decay\n0   -7.269605e+06  2538.197878            13             0.7",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>log_likelihood</th>\n      <th>perplexity</th>\n      <th>n_components</th>\n      <th>learning_decay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-7.269605e+06</td>\n      <td>2538.197878</td>\n      <td>13</td>\n      <td>0.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "lda_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying GridSearch for finding out best parameters for LDA"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing GridSearchCV from sklearn.model_selection\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating parameters for LDA\n",
    "params = {'n_components': [5, 7, 9, 10, 12, 14], 'learning_decay': [.3, .5, .7, .9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing evaluate LDA and passing parameters to it\n",
    "eval_lda = LatentDirichletAllocation()\n",
    "eval_lda = GridSearchCV(eval_lda, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "C:\\Users\\faisa\\Anaconda3\\envs\\AI2_course\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\nExecution took 18402.5295085907 seconds - (306.70882514317833 minutes), (5.111813752386306 hours)\n"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "# this will search for optimal parameters\n",
    "# Note: this process consumes a significant amount of time and resources\n",
    "start = time_elapsed_start()\n",
    "eval_lda.fit(term_matrix)\n",
    "time_elapsed_stop(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best Model's Params:  {'learning_decay': 0.7, 'n_components': 5}\nBest Log Likelihood Score:  -2491733.7206677482\nModel Perplexity:  2580.757106386333\n"
    }
   ],
   "source": [
    "# Best Model which gave highest score \n",
    "best_lda_model = eval_lda.best_estimator_\n",
    "\n",
    "# Model Parameters is used to store a list of parameter settings dicts for all the parameter candidates\n",
    "print(\"Best Model's Params: \", eval_lda.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", eval_lda.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(term_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time_elapsed_start()\n",
    "lda.fit(term_matrix)\n",
    "time_elapsed_stop(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time_elapsed_start()\n",
    "log_likelihood = lda.score(term_matrix)\n",
    "perplexity = lda.perplexity(term_matrix)\n",
    "time_elapsed_stop(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Log likelihood: {log_likelihood}\")\n",
    "print(f\"Perplexity: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing metrics in metrics dataframe\n",
    "lda_metrics_df.loc[-1] = [log_likelihood, perplexity, 12, 0.7]\n",
    "lda_metrics_df.index = lda_metrics_df.index + 1\n",
    "lda_metrics_df = lda_metrics_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring topics and their words"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 27,885 words in the vocabulary. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 topics with 27,885 words"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring a random topic"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_topic = lda.components_[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_chart(words, count, chart_title):\n",
    "    d = pd.DataFrame({\"Words\": words, \"Count\": count})\n",
    "    # Sort the dataframe by largest count\n",
    "    d = d.sort_values(by=[\"Count\"], ascending=False)\n",
    "    ax = d.plot.bar(y=\"Count\", x=\"Words\", title=chart_title, figsize=(15, 10), legend=True, fontsize=12, rot=1)\n",
    "    ax.set_xlabel(\"Frequent words\", fontsize=12)\n",
    "    ax.set_ylabel(\"Word count\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "probability_list = []\n",
    "\n",
    "for index in random_topic.argsort()[-15:]:\n",
    "    frequent_word = count_vectorizer.get_feature_names()[index]\n",
    "    print(frequent_word, sep=\" \")\n",
    "    word_list.append(frequent_word)\n",
    "    probability_list.append(index)\n",
    "    \n",
    "show_chart(word_list, probability_list, \"Word probability for first topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "probability_list = []\n",
    "\n",
    "top_number = 25\n",
    "count = 0\n",
    "for probability_number in lda.components_:\n",
    "    text_message = f\"Top words for topic {count} are : \"\n",
    "    print(text_message)    \n",
    "    for number in probability_number.argsort()[-top_number:]:\n",
    "        print([count_vectorizer.get_feature_names()[number]], end= \"\")\n",
    "    print(\"\\n\")  \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('AI2_course': conda)",
   "language": "python",
   "name": "python37664bitai2courseconda371d0ac7346d46c683e74ae2ba78d451"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}